---
title: 中间件面试要点
date: 2019-03-05 10:22:11
categories:
  - 中间件
tags:
  - 面试
---
中间件使用时常用问题，中间件核心原理
<!-- more -->
## 消息队列
## 消息队列常见问题
1. 消息队列的用途
- 应用解耦
- 异步处理
- 基于本地消息表的分布式事务

2. 

### rabbitmq
#### 集群配置
1. 默认集群间使用元数据同步, 会有单点故障问题
2. 使用ha-mode, 指定数据同步的方式,可以选择同步到所有节点和指定节点

#### 持久化机制
1. 队列持久化 (durable)
2. 消息持久化
3. 交换器持久化

***内存警告***
当内存超过阈值, 或磁盘剩余低于阈值, 会暂时阻塞(blocking)客户端连接,停止接收客户端消息.尝试进行内存换页

***内存换页***
当使用的内存将要到达阈值时, 将非持久化消息放入磁盘, 清除持久化消息内存副本以释放内存,都从磁盘读取.

***磁盘告警***
若磁盘剩余也低于阈值, 会阻塞客户端连接(blocked)

#### 常见问题
1. 消息乱序
出现的原因
- producer消息发送失败引起重发（有消息重发时）
- 由于网络原因，前面的消息先到达队列

2. 如何保证消息顺序消费
- 如果仅仅是按照消息投递顺序消费，不关心投递是否乱序，可以指定一个queue只由一个消费者消费，并且此消费者为单线程消费
- 如果需要根据消息业务id顺序消费，则可以按照类似于粘包拆包问题解决，先缓冲部分消息，等到所依赖的消息全部到达后一并处理。（如果由单消费者单线程可以在内存缓存，如果多消费者或多线程，可以在公共缓存或数据库等做缓冲）

3. 消息丢失
出现的原因
- 消费端处理消息出现异常，由于自动ack，此条消息不会重新投递到消息队列

解决办法
- 手动ack
- 应用层捕捉异常，重试处理消息或者告警

4. 如何保证producer端可靠发送
注意点
producer端接收确认有两种方式，同步，事务，异步(CallBackConfirm, ReturnConfirm)
同步：影响并发度
事务：影响并发度
异步：在等待ack时连接断开，无法确认消息是否真的发送

解决方法
在异步确认的基础上，记录消息发送状态（数据库或缓存），定时扫描消息表，达到一定时间未确认则重发。
此时会出现消息重复的问题，在消费端保证消息处理的幂等就好了。

5. 如何保证consumer端可靠消费
将acknowledge-mode设置为manual, 并在消息处理完成或者无法处理时手动ack或nack

## activemq
### 支持的消息协议
- AUTO (自动检测传输过来的消息协议)
- OpenWire (activemq默认协议, 支持tcp,udp,nio,vm等传输方式)
- AMQP
- Stomp
- MQTT (更轻量级, 服务质量定义Qos)

### 集群部署
- 主从
- cluster

### 持久化方式
- 数据库
- amq (基于文件存储, 但索引文件过大)
- kahaDB(基于文件系统, 替换了amq)


## 缓存中间件
### redis
#### 核心原理
基于Reator模型，单进程单线程，通过I/O多路复用模块实现单线程监听多个socket
{% asset_img redis线程模型.png %}

#### 常见问题
1. 为什么单线程如此高性能
- 主要基于操作系统api封装了多路复用模块，避免了I/O的阻塞
- 纯内存操作
- 单线程避免了线程切换的损耗

#### 持久化方式
1. rdb
dump内存数据到磁盘，恢复时直接将文件加载到内存

优点：恢复速度快
缺点：宕机后将损失最后一次持久化之后的数据

2. aof
将redis的所有操作记录到文件，恢复时重做redis命令

优点：宕机不会丢失数据
缺点：恢复慢

#### 主从同步过程
完全复制：
1. slave 发送sync到master
2. master fork子进程并dump内存生成rdb文件发送到slave
3. 在发送rdb期间产生的写命令缓冲到内存
4. 发送缓冲的写命令到slave

部分复制：
slave 发送的sync命令改为psync，master确认后发送剩余的rdb和缓冲的写命令

## zookeeper
### 分布式锁
1. 在资源节点下创建临时顺序节点
2. 获取所有字节点,判断是否是最小的
3. 若是最小的则获取锁,否则注册前一个节点的删除事件并阻塞
4. 监听到删除时间, 跳到步骤2做判断
5. 业务操作完成,释放锁,删除节点
{% asset_img zookeeper分布式锁 %}

### 选举机制
投票信息:
- logicalclock: 本地选举周期
- epoch: 选举周期(每次参与选举完leader后+1, 真正zxid的前32位)
- zxid: 数据id, 每次数据变动都会+1 (真正zxid的后32位, 真正zxid为64位)
- sid: 该投票所属的serverId
- leader: 提议的leader

比较规则:
1. epoch大的胜出
2. zxid大的胜出
3. sid大的胜出


